# YAMNet-Lite + Custom Head (17-Class Home Sound Classifier)

ì´ í”„ë¡œì íŠ¸ëŠ” Google YAMNetì˜ ì„ë² ë”©ì„ ê¸°ë°˜ìœ¼ë¡œ **17ê°œ ìƒí™œ ì†Œë¦¬ë§Œ ë¶„ë¥˜í•˜ëŠ” ì´ˆê²½ëŸ‰ ì˜¤ë””ì˜¤ ë¶„ë¥˜ê¸°**ë¥¼ êµ¬í˜„í•œ ê²ƒì…ë‹ˆë‹¤.  
ë¼ì¦ˆë² ë¦¬íŒŒì´Â·ì„ë² ë””ë“œ IoT í™˜ê²½ì—ì„œë„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ëª¨ë¸ì„ ìµœì í™”í–ˆìŠµë‹ˆë‹¤.

---

## ğŸš€ Features

- **YAMNet 256-dim ê²½ëŸ‰í™” ë°±ë³¸ ì‚¬ìš©**
- **17-class custom head TFLite ëª¨ë¸ (FP16, ~1.3MB)**
- WAV íŒŒì¼ ë¶„ë¥˜ / ì‹¤ì‹œê°„ ë§ˆì´í¬ ì…ë ¥ ë¶„ë¥˜ ì§€ì›
- TFLite Runtime ê¸°ë°˜ Edge ë””ë°”ì´ìŠ¤ ìµœì í™”
- í´ë˜ìŠ¤ë³„ **AUC / AUPR ì„±ëŠ¥ ì œê³µ**

---

## ğŸ”§ Installation

### 1) ê°€ìƒí™˜ê²½ ìƒì„±
```bash
python3 -m venv .venv
source .venv/bin/activate

2) íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

ğŸ—‚ï¸ Project Structure
YAMNET/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ yamnet/
â”‚   â”‚   â”œâ”€â”€ yamnet.tflite
â”‚   â”‚   â””â”€â”€ yamnet-256.tflite
â”‚   â””â”€â”€ head/
â”‚       â”œâ”€â”€ head_1024_fp16.tflite
â”‚       â””â”€â”€ head_256_fp16.tflite
â”‚
â”œâ”€â”€ runs_multi/
â”‚   â””â”€â”€ per_class_eval_1024.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ eval_per_class.py
â”‚   â”œâ”€â”€ inspect_yamnet_tflite.py
â”‚   â”œâ”€â”€ realtime_infer_mic.py
â”‚   â”œâ”€â”€ run_yamnet_plus_head_tflite.py
â”‚   â””â”€â”€ train_head_1024.py
â”‚
â”œâ”€â”€ scripts/data/
â”‚   â”œâ”€â”€ balanced_train_segments.csv
â”‚   â”œâ”€â”€ class_labels_indices.csv
â”‚   â””â”€â”€ ontology.json
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

â–¶ï¸ How to Run
1) WAV íŒŒì¼ ë¶„ë¥˜
python scripts/run_yamnet_plus_head_tflite.py

2) ì‹¤ì‹œê°„ ë§ˆì´í¬ ê¸°ë°˜ ë¶„ë¥˜
python scripts/realtime_infer_mic.py

ğŸ§  Model Overview
ğŸ”¹ YAMNet Backbone (256-dim)

Google AudioSet ê¸°ë°˜ ëª¨ë¸

ì›ë˜ 1024-dim â†’ 256-dim ê²½ëŸ‰í™”ëœ ë²„ì „ë„ ì œê³µ

ì„ë² ë”©ì„ Custom Headì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©

ğŸ”¹ Custom Head (17-Class, FP16)

YAMNet ì„ë² ë”©ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ 17ê°œ ê°€ì •ìƒí™œ ì†Œë¦¬ ë¶„ë¥˜

FP16 TFLite (~1.3MB)ë¡œ ëª¨ë°”ì¼Â·IoT í™˜ê²½ ìµœì í™”

Raspberry Pi 4/5, Android, MCU ë³´ë“œ ë“±ì—ì„œ ì‹¤ì‹œê°„ ê°€ëŠ¥

ğŸ“Š Evaluation Results (AUC / AUPR)

runs_multi/per_class_eval_1024.json ë¶„ì„ ê²°ê³¼:

âœ” ì „ì²´ ìš”ì•½
{
  "num_samples": 22212,
  "macro_auc": 0.9898577788296867,
  "macro_aupr": 0.9705225053955527
}

âœ” ì£¼ìš” í´ë˜ìŠ¤ë³„ AUC / AUPR ìš”ì•½
Class	AUC	AUPR
door	0.9878	0.9579
dishes	0.9897	0.9614
cutlery	0.9830	0.9533
chopping	0.9796	0.9547
frying	0.9913	0.9761
microwave	0.9941	0.9743
blender	0.9947	0.9886
water_tap	0.9897	0.9615
sink	0.9935	0.9665
toilet_flush	0.9962	0.9911
telephone	0.9953	0.9869
chewing	0.9849	0.9659
speech	0.9902	0.9693
television	0.9819	0.9566
footsteps	0.9788	0.9445
vacuum	0.9980	0.9957
hair_dryer	0.9981	0.9940
ğŸ“œ Description of Key Files
ğŸ“ models/yamnet/

yamnet.tflite: Google ì›ë³¸ 1024-dim YAMNet ëª¨ë¸

yamnet-256.tflite: ì„ë² ë”© 256ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•œ ê²½ëŸ‰í™” ë°±ë³¸

ğŸ“ models/head/

head_1024_fp16.tflite: 1024-dim YAMNet ì„ë² ë”©ìš© custom head (ìµœì¢… ëª¨ë¸)

head_256_fp16.tflite: 256-dim ì„ë² ë”©ìš© custom head (ë³´ì¡° ëª¨ë¸)

ğŸ“ scripts/
ğŸ”¹ train_head_1024.py

YAMNet ì„ë² ë”©ì„ ì…ë ¥ ë°›ì•„ 17-class head í•™ìŠµ

ê²°ê³¼ë¬¼ì„ TFLite FP16ìœ¼ë¡œ ë³€í™˜

ğŸ”¹ run_yamnet_plus_head_tflite.py

WAV íŒŒì¼ì„ ì…ë ¥ë°›ì•„
YAMNet â†’ Head TFLite ìˆœìœ¼ë¡œ ë¶„ë¥˜ ì²˜ë¦¬í•˜ëŠ” ë‹¨ì¼ íŒŒì´í”„ë¼ì¸

ğŸ”¹ realtime_infer_mic.py

ì‹¤ì‹œê°„ 16kHz ë§ˆì´í¬ ë°ì´í„°ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•´ì„œ ë¶„ë¥˜

Raspberry Pi í™˜ê²½ì—ì„œ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥

ğŸ”¹ inspect_yamnet_tflite.py

YAMNet TFLite êµ¬ì¡°(ì…ì¶œë ¥ shape ë° tensor index) ìë™ ë¶„ì„

ğŸ”¹ eval_per_class.py

í´ë˜ìŠ¤ë³„ AUC / AUPR ê³„ì‚°

ğŸ“ scripts/data/
balanced_train_segments.csv

AudioSet Balanced train ëª©ë¡

class_labels_indices.csv

521ê°œ ë ˆì´ë¸” ì¸ë±ìŠ¤ ì •ì˜

ontology.json

AudioSet Ontology êµ¬ì¡°

ğŸ“¦ requirements.txt (ì˜ˆì‹œ ë‚´ìš©)
tensorflow==2.15.0
tensorflow-hub
numpy
soundfile
sounddevice
tflite-runtime
scikit-learn

ğŸ“„ License

MIT License

ğŸ“¬ Contact

ë¬¸ì˜: your-email@example.com

GitHub Issuesë¡œ ë¬¸ì˜ ê°€ëŠ¥
